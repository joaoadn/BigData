{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2665f558-53d8-4586-bfa4-43830aa5384f",
   "metadata": {},
   "source": [
    "# EX4-BATCH: Introduction to Spark programming with HDFS Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f50ba8f-805e-45ec-abba-a08281baa4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext not defined\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    print(\"SparkContext not defined\")\n",
    "\n",
    "sc = SparkContext(appName=\"HDFS_Log_Analysis\", master=\"local[*]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1ca26",
   "metadata": {},
   "source": [
    "### Loading HDFS Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0c1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total log lines: 5\n",
      "First 3 lines:\n",
      "081109 203432 154 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\n",
      "081109 203432 156 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 67108864 from /10.250.10.6\n",
      "081109 203432 157 WARN dfs.DataNode$DataXceiver: Slow receiver detected\n"
     ]
    }
   ],
   "source": [
    "hdfs_logs = [\n",
    "    \"081109 203432 154 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\",\n",
    "    \"081109 203432 156 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 67108864 from /10.250.10.6\",\n",
    "    \"081109 203432 157 WARN dfs.DataNode$DataXceiver: Slow receiver detected\",\n",
    "    \"081109 203433 158 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862907 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\",\n",
    "    \"081109 203433 159 ERROR dfs.DataNode$DataXceiver: Error receiving block blk_-1608999687919862907\"\n",
    "]\n",
    "\n",
    "logs_rdd = sc.parallelize(hdfs_logs)\n",
    "print(\"Total log lines:\", logs_rdd.count())\n",
    "print(\"First 3 lines:\")\n",
    "for line in logs_rdd.take(3):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49705c",
   "metadata": {},
   "source": [
    "### Advanced HDFS Log Analysis Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121f9e9",
   "metadata": {},
   "source": [
    "**1. Extract Block IDs from Logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f8a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block IDs in logs:\n",
      "blk_-1608999687919862906\n",
      "blk_-1608999687919862907\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_block_id(line):\n",
    "    match = re.search(r'blk_[-0-9]+', line)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "block_ids = logs_rdd.map(extract_block_id).filter(lambda x: x is not None).distinct()\n",
    "print(\"Block IDs in logs:\")\n",
    "for block_id in block_ids.collect():\n",
    "    print(block_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6284f5fc",
   "metadata": {},
   "source": [
    "**2. Count Log Messages by Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c015647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log level counts:\n",
      "INFO: 3\n",
      "WARN: 1\n",
      "ERROR: 1\n"
     ]
    }
   ],
   "source": [
    "log_levels = logs_rdd.map(lambda line: line.split()[3])\n",
    "level_counts = log_levels.countByValue()\n",
    "print(\"Log level counts:\")\n",
    "for level, count in level_counts.items():\n",
    "    print(f\"{level}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9d7e3",
   "metadata": {},
   "source": [
    "**3. Find Error Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d33e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error messages:\n",
      "081109 203433 159 ERROR dfs.DataNode$DataXceiver: Error receiving block blk_-1608999687919862907\n"
     ]
    }
   ],
   "source": [
    "error_logs = logs_rdd.filter(lambda line: \"ERROR\" in line)\n",
    "print(\"Error messages:\")\n",
    "for log in error_logs.collect():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bda564",
   "metadata": {},
   "source": [
    "**4. Extract Timestamps and Create Time Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b4830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log timestamps:\n",
      "081109 203432\n",
      "081109 203432\n",
      "081109 203432\n",
      "081109 203433\n",
      "081109 203433\n"
     ]
    }
   ],
   "source": [
    "timestamps = logs_rdd.map(lambda line: ' '.join(line.split()[0:2]))\n",
    "print(\"Log timestamps:\")\n",
    "for ts in timestamps.collect():\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975a8e4",
   "metadata": {},
   "source": [
    "**5. Analyze Block Transfer Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43af334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block sizes mentioned:\n",
      "67108864\n"
     ]
    }
   ],
   "source": [
    "def extract_size(line):\n",
    "    match = re.search(r'size (\\d+)', line)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "block_sizes = logs_rdd.map(extract_size).filter(lambda x: x is not None)\n",
    "print(\"Block sizes mentioned:\")\n",
    "for size in block_sizes.collect():\n",
    "    print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cadd8",
   "metadata": {},
   "source": [
    "**6. Count Events by Source IP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f9f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events by source IP:\n",
      "/10.250.10.6: 5\n"
     ]
    }
   ],
   "source": [
    "def extract_src_ip(line):\n",
    "    match = re.search(r'src: (\\S+)', line)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "src_ips = logs_rdd.map(extract_src_ip).filter(lambda x: x is not None)\n",
    "ip_counts = src_ips.countByValue()\n",
    "print(\"Events by source IP:\")\n",
    "for ip, count in ip_counts.items():\n",
    "    print(f\"{ip}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e992156",
   "metadata": {},
   "source": [
    "**7. Find Slow Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6152ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow operations detected:\n",
      "081109 203432 157 WARN dfs.DataNode$DataXceiver: Slow receiver detected\n"
     ]
    }
   ],
   "source": [
    "slow_ops = logs_rdd.filter(lambda line: \"Slow\" in line or \"WARN\" in line)\n",
    "print(\"Slow operations detected:\")\n",
    "for op in slow_ops.collect():\n",
    "    print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e1e47",
   "metadata": {},
   "source": [
    "**8. Calculate Average Time Between Events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e475c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time between events (seconds): 1.25\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_time(line):\n",
    "    time_str = ' '.join(line.split()[0:2])\n",
    "    return datetime.strptime(time_str, \"%y%m%d %H%M%S\")\n",
    "\n",
    "times = logs_rdd.map(parse_time).collect()\n",
    "diffs = [(times[i+1] - times[i]).seconds for i in range(len(times)-1)]\n",
    "avg_diff = sum(diffs)/len(diffs) if diffs else 0\n",
    "print(f\"Average time between events (seconds): {avg_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eaf5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
